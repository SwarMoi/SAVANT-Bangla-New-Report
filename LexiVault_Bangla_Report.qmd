---
title: "Bangla Corpus"
author: "Swarnendu Moitra"
format:
  html:
    toc: true
    code-fold: true
    code-tools: true
    embed-resources: true
execute:
  echo: true
  error: false
  warning: false
  cache: false
---

### Objective

The aim of is to construct a lexical database for the low-resource language Bangla by leveraging and enhancing available Natural Language Processing (NLP) tools. The primary objective is to derive lexical statistics such as stem frequency, whole word frequency, and transitional probabilities. A secondary objective is to compute additional lexical statistics, including n-gram frequencies.

### Data Source

Our principal dataset is sourced from the IndicNLP Bangla Newspaper Corpus (<https://github.com/AI4Bharat/indicnlp_corpus>), encompassing **836 million tokens**.

### Methodology

#### Data Preprocessing

##### Data Cleaning

Although the dataset had been preprocessed, further cleaning was undertaken to eliminate metadata, HTML tags, and inconsistent formatting. We normalized the text by standardizing different forms of text variations, such as handling spelling inconsistencies.

##### Tokenization

We generated two primary corpora for analysis:

1.  **Tokenized Sentences Corpus**: Created by identifying sentence endings using the Bangla punctuation mark (।) and placing each sentence on a new line, saved as `tokenized_sen.txt`.

2.  **Tokenized Words Corpus**: Created by placing each word on a separate line, saved as `tokenized_words.txt`.

## Attempt 1: Initial Lexical Statistics Calculation

For our initial attempt at calculating lexical statistics, we employed pattern matching techniques:

-   **Whole Word Frequency**: Exact matches for the stimuli were counted.

-   **Stem Frequency**: Utilized the Python `text` function `contains` for pattern matching. Counters were incremented for each match corresponding to either the whole word frequency or stem frequency.

To normalize the resultant data, both whole word frequency and stem frequency counts were divided by 836 million to derive Parts Per Million (PPM) counts.

##### Issues Encountered

The stem frequency counts were found to be significantly inflated.

## Attempt 2: Enhanced Stemming Approach

To address the issues encountered in Attempt 1, we focused on using a stemming algorithm. We evaluated several Bangla stemmers and selected the `bangla-stemmer` (available at <https://pypi.org/project/bangla-stemmer/>) for its relative accuracy of `56%.`

![Verbal Afiixes](images/Screenshot%202024-08-08%20at%2012.35.26.png)

##### Stemming Modifications

-   The `bangla-stemmer` is a rule-based stemmer that originally stripped Bangla inflectional suffixes.

-   We extended the stemmer to include rules for prefix stripping and derivational affix stripping.

-   After manually checking and annotating 1230 highest frequency words in Bangla, the accuracy of our modified stemmer increased to approximately `76%`.

**Note**: The stemmer operates independently of word categories and applies a generalized stemming process.

##### Issues Encountered

Despite improvements, the stemmer exhibited over-stemming, particularly for nominal words due to the differential affix combination rules in Bangla nouns versus verbs. Additionally, handling compound words presented further challenges.

## Attempt 3: Varied approch for Stemming + POS

To address the above issues, we are presently testing and training POStagger with the following stemmers

![Stemmers tested but the accuracy is based on predominantly verbal inlections](images/Screenshot%202024-08-08%20at%2012.32.58.png)

![](images/Screenshot%202024-08-08%20at%2012.38.43.png){fig-align="center"}

Following <https://aclanthology.org/2020.icon-main.55/> proposed algorithm we are presently upgrading our stemmer.

## Remarks

Specific issues remain with the stemmer

1.  Identifying/Upgrade existing POS and stemmer to address compound stemming.

2.  Create an exhaustive exception list for irregular word forms and compounds which would bypass the stemmer if matched and with output human annotated values.

3.  For validation, train a smaller POS annotated dataset for calculating Parsing Accuracy.

4.  Upgrade our stemmer with the proposed algo for category specific affix stripping and adding derivational rules.

[Github Repo for Bangla Stemmer](https://github.com/SwarMoi/LexiVault-Bangla-stemmer "LexiVault Bangla Stemmer")

# Stimuli Selection

The Grammatical condition consists of existing nouns with prefixes প্রতি prôti and দুঃ duḥ. We used Sketch Engine’s preloaded Bangla Corpus to query for nouns beginning with the two prefixes using the web-based interface (Kilgariff et al., 2014). This query found 429 words beginning with the string প্রতি prôti and 929 beginning with the string দু্ঃ duḥ or its allomorphs (দুস্, দশ্, দুর্, দুষ্ ). We manually removed duplicate words, words that contained additional inflectional morphology or words that did not actually contain the prefixes, resulting in 48 bi-morphemic words beginning with প্রতি prôti and 36 beginning with দু্ঃ duḥ. To ensure the existence and meaning of these words, both stems and whole words items were checked with a Bangla online dictionary (https://www.english-bangla.com/browse/bntoen/). Of these 84 nouns, 6 were rejected because they were not present in the dictionary. This resulted in 78 total words consisting of প্রতি prôti or দু্ঃ duḥ and an abstract noun stem for the initial candidate set of grammatical stimuli.

The semantic violation condition (SemViol) was created by adding the same two prefixes to nouns which mismatch the prefix’s conceptual semantic requirement that it attach to stems referring to abstract entities. For example, দু্ঃ duḥ added to the concrete noun কলম kôlôm ‘pen’ creates the pseudoword \*দুঃকলম duḥkôlôm. Concrete noun stems were generated using the MRC Psycholinguistic Database (Coltheart 1981), following a similar procedure used for research in Italian by Rosa et al. (2010). We began with identifying the 325 English nouns that were rated the highest for concreteness (all greater than 450 for concreteness on a scale of 100-750) . We then translated them to Bangla, and excluded any nouns that were identifiable as noun-noun compounds or English borrowings. We also excluded nouns that were poor translations, lacked clear cultural analogs in Bengali culture (e.g., farmyard), or that were not used in colloquial registers. This resulted in 153 concrete nouns.

With these 153 concrete nouns plus the 78 abstract noun stems with prefixes দু্ঃ duḥ and প্রতি prôti removed (231 nouns total). 30 (17 female) adult native speakers of Bangla average age 27.32 yrs (2 participants age were excluded as they responded 0) were recruited via email from West Bengal, India for a norming study where the concreteness of noun stems were rated on a 7-point Likert scale (1 corresponded to low concreteness and 7 high concreteness). Participants were also asked to rate their language proficiency (speaking and writing) on a scale of 1 - 5. Native language proficiency of 3 and above was considered in the final analysis (0 exclusions). 300 rupees (£3) for their participation via UPI. The instructions from Spreen & Schulz (1966) were translated into Bangla. The English is below:

Nouns may refer to persons, places and things that can be seen, heard, felt, smelled or tasted or to more abstract concepts that cannot be experienced by our senses. The purpose of this experiment is to rate a list of words with respect to "concreteness" in terms of sense-experience. Any word that refers to objects, materials or persons should receive a high concreteness rating; any word that refers to an abstract concept that cannot be experienced by the senses should receive a low concreteness rating. Think of the words "chair" and "independence." "Chair" can be experienced by our senses and therefore should be rated as high concrete; "independence" cannot be experienced by the senses as such and therefore should be rated as low concrete (or abstract).

Participants were shown the consent form and then were asked to fill the demographic questionnaire. The participants then rated 231 Nouns, each noun appearing in the middle screen one by one with 500ms ISI. The likert scale was placed below Nouns numbered 1-7 as buttons from left to right; Low concrete and High concrete were written (in Bangla) on each end of the likert scale respectively.

Of the 78 abstract noun stems obtained by removing দু্ঃ duḥ and প্রতি prôti, those that were scored on average less than 3.5 on the Likert scale were kept, resulting in 77 items. Of these 77, 7 were excluded because they were bound morphemes and therefore could not be easily judged in isolation resulting in 70 candidate items.

Of the 153 concrete nouns translated from the MRC Psycholinguistic Database, those that scored on average more than 4 on the Likert scale were kept, resulting in 138 candidate items. We then created semantic violations by adding the prefixes দু্ঃ duḥ and with প্রতি prôti to create 138 SemViol candidate items.

The category violation condition (CatViol) is achieved by adding the nominal prefixes to adjectival stems, e.g., দু্ঃ duḥ added to লাল lal ‘red’ to create the pseudoword \*দুর্লাল durlal. We initially created a list of 110 candidates by attaching দু্ঃ duḥ and প্রতি prôti to simple, monomorphemic adjectival stems varying in length and frequency.

We then constructed a candidate list of 121 morphologically complex concrete noun filler items. The filler items were morphologically complex and concrete to ensure that there were both grammatical stimuli with concrete stems and ungrammatical stimuli with concrete stems. We made this list by taking 61 of the highest rated concrete nouns from the rating study and 60 additional concrete nouns were translated into Bangla from English from the MRC database. We included the morphologically complex stems that were excluded from the SemViol candidates in this list of fillers. For the concrete stems that were monomorphemic, we added inflectional morphology or constructed noun-noun compounds by adding another nominal stem.

After constructing the list of candidate CatViol, SemViol, Grammatical, and filler stimuli, we manually removed items to ensure that we had similar numbers of items for each condition and prefix, and to control for several variables. Within each prefix, we matched CatViol, SemViol, and Grammatical stems on relative frequency (all ps \> 0.2). Stem relative frequency was estimated by searching the Bangla IndicNLP corpus (Kakwani 2020) for all words that contain the stem as a substring.We also ensured that the whole word lengths were not significantly different between Grammatical, SemViol, and CatViol conditions within each prefix by calculating number of characters using the nchar() function in R (all ps \> 0.2). We also ensured that the whole word lengths were not significantly different between the grammatical fillers, grammatical দু্ঃ duḥ and grammatical প্রতি prôti items (all ps \> 0.2). This resulted in 26 Grammatical items beginning with দু্ঃ duḥ, 34 beginning with প্রতি prôti, 38 items for each violation condition per prefix, and 92 grammatical filler items, resulting in 304 items (152 grammatical, 152 ungrammatical).
